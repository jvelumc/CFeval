# CFeval

Prediction under interventions considers estimating what a subject’s
risk would be if they were to receive a certain treatment. Likewise one
may be interested in assessing predictive performance in a setting where
all individuals were to receive a certain treatment option. This is
challenging, as only the outcome of the realized treatment level can be
observed in the data, and outcomes under any treatment option are
counterfactual.(Keogh, van Geloven, DOI 10.1097/EDE.0000000000001713).
This R package facilitates assessing counterfactual performance of
predictions.

## Installation

You can install the development version of CFeval from
[GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("jvelumc/CFeval")
```

## Example

Simulate example data for binary outcome $Y$ and point treatment $A$,
with the relation between $A$ and $Y$ confounded by variable $L$.
Variable $P$ is a prognostic variable for only the outcome. The
treatment reduces the risk on a bad outcome ($Y = 1$) in this simulated
example.

![Figure 1. DAG for toy example](reference/figures/dag.png)

Figure 1. DAG for toy example

``` r
n <- 1000

df_dev <- data.frame(id = 1:n)
df_dev$L <- rnorm(n)
df_dev$A <- rbinom(n, 1, plogis(2*df_dev$L))
df_dev$P <- rnorm(n)
df_dev$Y <- rbinom(n, 1, plogis(0.5 + df_dev$L + 1.25 * df_dev$P - 0.9*df_dev$A))
```

We also need something to validate. We will create a couple of models
using the development data.

``` r
# naive model, not accounting for confounding variable L
naive_model <- glm(Y ~ A + P, family = "binomial", data = df_dev)

# causal model, accounting for L by IP-weighting
trt_model <- glm(A ~ L, family = "binomial", data = df_dev)
propensity_score <- predict(trt_model, type = "response")
df_dev$iptw <- 1 / ifelse(df_dev$A == 1, propensity_score, 1 - propensity_score)
causal_model <- glm(Y ~ A + P, family = "binomial", data = df_dev, weights = iptw)
#> Warning in eval(family$initialize): non-integer #successes in a binomial glm!

# a model that randomly predicts something, not very good probably
random_predictions <- runif(5000, 0, 1)
```

Note that according to the naive model, we should not treat anybody, as
patients that get treated have a higher risk for the outcome. The causal
model correctly infers that treatment benefits patients.

``` r
print(coefficients(naive_model))
#> (Intercept)           A           P 
#> -0.09438097  0.25710271  0.98079027
print(coefficients(causal_model))
#> (Intercept)           A           P 
#>   0.3569683  -0.9224453   0.9183316
```

We are now interested in how the models perform in an external
validation dataset. This dataset can have a different causal structure
from the original development dataset. In this example, we simulate that
patients are treated more aggressively. The relation between the outcome
and the other variables is the same.

``` r
n <- 5000

df_val <- data.frame(id = 1:n)
df_val$L <- rnorm(n)
df_val$A <- rbinom(n, 1, plogis(0.5 + 2*df_val$L))
df_val$P <- rnorm(n)
df_val$Y <- rbinom(n, 1, plogis(0.5 + df_val$L + 1.25 * df_val$P - 0.9*df_val$A))
```

The question that we would like to have answered is the following:

How well does our prediction model perform if we were to treat nobody?

The CFeval package aims to provide tools to answer questions like this.
The main function
[`CFscore()`](https://jvelumc.github.io/CFeval/reference/CFscore.md) can
be used for this.

``` r
library(CFeval)

CFscore(
  object = list(
    "random" = random_predictions,
    "naive model" = naive_model,
    "causal model" = causal_model
  ),
  data = df_val, 
  outcome_formula = Y ~ 1,
  treatment_formula = A ~ L, 
  treatment_of_interest = 0
)
#> Estimation of the performance of the prediction model in a
#>  counterfactual (CF) dataset where everyone's treatment A was set to 0.
#> The following assumptions must be satisfied for correct inference:
#> - Conditional exchangeability requires that given IP-weights are
#>  sufficient to adjust for confounding and selection bias between
#>  treatment and outcome.
#> - Positivity (assess $ipt$weights for outliers)
#> - Consistency
#> - No interference
#> - Correctly specified propensity formula. Estimated treatment model is
#>  logit(A) = 0.48 + 1.99*L. See also $ipt$model
#> 
#>         model   auc brier oeratio
#>    null model 0.500 0.244    1.00
#>        random 0.519 0.319    1.17
#>   naive model 0.752 0.208    1.21
#>  causal model 0.752 0.198    1.01
```

![](reference/figures/README-unnamed-chunk-6-1.png)

As we see, the causal model has best calibration and Brier score.

Note that the AUC of the naive model and the causal model are equal. AUC
is driven entirely by how individuals’ model predictions are ranked, not
by the magnitude of the predictions. In this simple setting, P is the
only variable driving prognostic differences between individuals (in a
pseudopopulation where we counterfactually set everyone’s treatment
status to $0$). While the models have different coefficients for P,
individuals are ranked in exactly the same way.

$CFscore{()}$ also supports stabilized weights and bootstrapping for
confidence intervals. Right censored survival data and cox models are
also supported.

``` r
CFscore(
  object = list(
    "random" = random_predictions,
    "naive model" = naive_model,
    "causal model" = causal_model
  ),
  data = df_val, 
  outcome_formula = Y ~ 1,
  treatment_formula = A ~ L, 
  treatment_of_interest = 0,
  bootstrap = 50,
  bootstrap_progress = FALSE,
  stable_iptw = TRUE,
  quiet = TRUE
)
#> 
#> auc
#> 
#>         model   auc lower upper
#>    null model 0.500 0.500 0.500
#>        random 0.519 0.481 0.569
#>   naive model 0.752 0.717 0.786
#>  causal model 0.752 0.717 0.786
#> 
#> brier
#> 
#>         model brier lower upper
#>    null model 0.244 0.237 0.248
#>        random 0.319 0.296 0.341
#>   naive model 0.208 0.194 0.223
#>  causal model 0.198 0.189 0.208
#> 
#> oeratio
#> 
#>         model oeratio lower upper
#>    null model    1.00 0.957  1.07
#>        random    1.17 1.114  1.26
#>   naive model    1.21 1.159  1.29
#>  causal model    1.01 0.968  1.08
```

![](reference/figures/README-unnamed-chunk-7-1.png)![](reference/figures/README-unnamed-chunk-7-2.png)![](reference/figures/README-unnamed-chunk-7-3.png)![](reference/figures/README-unnamed-chunk-7-4.png)![](reference/figures/README-unnamed-chunk-7-5.png)

# Package index

## All functions

- [`CFscore()`](https://jvelumc.github.io/CFeval/reference/CFscore.md) :
  Counterfactual validation score
- [`ipt_weights()`](https://jvelumc.github.io/CFeval/reference/ipt_weights.md)
  : Get the inverse probability of treatment weights

# Articles

### All vignettes

- [CFeval](https://jvelumc.github.io/CFeval/articles/CFeval.md):
